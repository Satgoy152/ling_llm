{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in 2003\n",
      "Total points for 2004: 47\n",
      "Total points for 2005: 60\n",
      "Total points for 2006: 81\n",
      "Total points for 2007: 35\n",
      "Total points for 2008: 69\n",
      "Total points for 2009: 65\n",
      "Total points for 2010: 72\n",
      "Total points for 2011: 57\n",
      "Total points for 2012: 105\n",
      "Total points for 2013: 44\n",
      "Total points for 2014: 107\n",
      "Total points for 2015: 126\n",
      "Total points for 2016: 89\n",
      "Total points for 2017: 61\n",
      "Total points for 2018: 87\n",
      "Total points for 2019: 142\n",
      "Error in 2020\n",
      "Total points for 2021: 99\n",
      "Total points for 2022: 86\n",
      "Total points for 2023: 82\n",
      "Total questions: 1031\n",
      "Total type 1: 546\n",
      "Total type 2: 453\n",
      "Total type 3: 31\n"
     ]
    }
   ],
   "source": [
    "path = \"..\"\n",
    "# get data from problem count from classification file\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(path)\n",
    "total_qs = 0\n",
    "total_type_1 = 0\n",
    "total_type_2 = 0\n",
    "total_type_3 = 0\n",
    "for i in range(2003, 2024):\n",
    "    try: \n",
    "        with open(f\"{path}/iol_{i}/iol_{i}_classification.txt\", \"r\") as f:\n",
    "            data = f.readlines()\n",
    "            count_data = data[-4:]\n",
    "            total = int(count_data[0].split(\":\")[1].strip())\n",
    "            type_1 = int(count_data[1].split(\":\")[1].strip())\n",
    "            type_2 = int(count_data[2].split(\":\")[1].strip())\n",
    "            type_3 = int(count_data[3].split(\":\")[1].strip())\n",
    "            total_qs += total\n",
    "            total_type_1 += type_1\n",
    "            total_type_2 += type_2\n",
    "            total_type_3 += type_3\n",
    "            points = type_1 + type_2*2 + type_3*2\n",
    "            print(f\"Total points for {i}: {points}\")\n",
    "        # with open(f\"{path}/iol_{i}/iol_{i}_classification.txt\", \"a\") as f:\n",
    "        #     f.write(f\"\\nTotal points: {points}\")\n",
    "    \n",
    "    except:\n",
    "        print(f\"Error in {i}\")\n",
    "\n",
    "print(f\"Total questions: {total_qs}\")\n",
    "print(f\"Total type 1: {total_type_1}\")\n",
    "print(f\"Total type 2: {total_type_2}\")\n",
    "print(f\"Total type 3: {total_type_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def parse_grading_text_from_file(file_path):\n",
    "    # Create a structure to hold the final result\n",
    "    result = {}\n",
    "    \n",
    "    current_problem = None\n",
    "    current_part = None\n",
    "    current_question = None\n",
    "    current_data = {}\n",
    "\n",
    "    # Read the content from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Process each line\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Clean leading/trailing spaces\n",
    "\n",
    "        # Match \"Problem X:\"\n",
    "        problem_match = re.match(r'^Problem (\\d+):', line)\n",
    "        if problem_match:\n",
    "            current_problem = f\"Problem {problem_match.group(1)}\"\n",
    "            result[current_problem] = {}\n",
    "            current_part = None  # Reset current part and question when a new problem starts\n",
    "            current_question = None\n",
    "            continue\n",
    "\n",
    "        # Match \"Part X:\" where X can be a letter or a number\n",
    "        part_match = re.match(r'^Part ([a-zA-Z0-9]+):', line)\n",
    "        if part_match:\n",
    "            current_part = f\"Part {part_match.group(1)}\"\n",
    "            result[current_problem][current_part] = {}\n",
    "            current_question = None  # Reset question for this part\n",
    "            continue\n",
    "\n",
    "        # Ensure that there is a current problem and part before proceeding\n",
    "        if not current_problem or not current_part:\n",
    "            continue\n",
    "\n",
    "        # Match question number (e.g., 1, 2, 3, ...) or detect the absence of a question number\n",
    "        question_match = re.match(r'^(\\d+):', line)\n",
    "        if question_match:\n",
    "            current_question = question_match.group(1)\n",
    "            current_data = {}\n",
    "            result[current_problem][current_part][current_question] = current_data\n",
    "            continue\n",
    "\n",
    "        # Handle case when no question number exists (direct Classification under Part)\n",
    "        if not current_question:\n",
    "            current_data = result[current_problem][current_part]\n",
    "        \n",
    "        # Match Classification, LLM Answer, Real Answer, and Grade\n",
    "        classification_match = re.match(r'^Classification:\\s*(.+)', line)\n",
    "        llm_answer_match = re.match(r'^LLM Answer:\\s*(.+)', line)\n",
    "        real_answer_match = re.match(r'^Real Answer:\\s*(.+)', line)\n",
    "        grade_match = re.match(r'^Grade:\\s*(\\d+)', line)\n",
    "\n",
    "        if classification_match:\n",
    "            current_data[\"Classification\"] = classification_match.group(1)\n",
    "        elif llm_answer_match:\n",
    "            current_data[\"LLM Answer\"] = llm_answer_match.group(1)\n",
    "        elif real_answer_match:\n",
    "            current_data[\"Real Answer\"] = real_answer_match.group(1)\n",
    "        elif grade_match:\n",
    "            current_data[\"Grade\"] = int(grade_match.group(1))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "# load to yaml helper func\n",
    "def text_to_json(path):\n",
    "    try:\n",
    "        parsed_data = parse_grading_text_from_file(path)\n",
    "        json_text = json.dumps(parsed_data, indent=4)\n",
    "        return json.loads(json_text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error parsing text for path {path}\")\n",
    "        return None\n",
    "\n",
    "# function to get scores and data from graded data\n",
    "def grad_parser(graded_data: json):\n",
    "    json_obj = graded_data\n",
    "    total_score = 0\n",
    "    total_possible = 0\n",
    "    total_questions = 0\n",
    "    type1_right = 0\n",
    "    type1_possible = 0\n",
    "    type2_right_b = 0\n",
    "    type2_right_d = 0\n",
    "    type2_right_a = 0\n",
    "    type2_possible = 0\n",
    "    type3_right = 0\n",
    "    type3_possible = 0\n",
    "    for problem in json_obj:\n",
    "        if problem[0:7] != \"Problem\":\n",
    "            continue\n",
    "        total_questions += 1\n",
    "        for part in json_obj[problem]:\n",
    "            part_score = 0\n",
    "            part_possible = 0\n",
    "            for question in json_obj[problem][part]:\n",
    "                if question[0:4] == \"Clas\":\n",
    "                    try:\n",
    "                        get_grade = int(json_obj[problem][part]['Grade'][0])\n",
    "                    except:\n",
    "                        get_grade = json_obj[problem][part]['Grade']\n",
    "                        \n",
    "                    if json_obj[problem][part]['Classification'] == \"Type 1\":\n",
    "                        part_score += get_grade\n",
    "                        type1_right += get_grade\n",
    "                        part_possible += 1\n",
    "                        type1_possible += 1\n",
    "                    elif json_obj[problem][part]['Classification'] == \"Type 2\":\n",
    "                        overlap_d = 2 * SequenceMatcher(None, json_obj[problem][part]['LLM Answer'], json_obj[problem][part]['Real Answer']).ratio()\n",
    "                        # use bleu score instead\n",
    "                        overlap_b = 2 * sentence_bleu([json_obj[problem][part]['Real Answer'].split()], json_obj[problem][part]['LLM Answer'].split())\n",
    "                        part_score += overlap_d\n",
    "                        part_possible += 2\n",
    "                        type2_right_b += overlap_b\n",
    "                        type2_right_a += get_grade\n",
    "                        type2_right_d += overlap_d\n",
    "                        type2_possible += 2\n",
    "                    elif json_obj[problem][part]['Classification'] == \"Type 3\":\n",
    "                        part_score += get_grade\n",
    "                        part_possible += 2\n",
    "                        type3_right += get_grade\n",
    "                        type3_possible += 2\n",
    "                    break\n",
    "                # grading\n",
    "                try:\n",
    "                    get_grade = int(json_obj[problem][part][question]['Grade'][0])\n",
    "                except:\n",
    "                    get_grade = json_obj[problem][part][question]['Grade']\n",
    "                    \n",
    "                if json_obj[problem][part][question]['Classification'] == \"Type 1\":\n",
    "                    part_score += get_grade\n",
    "                    type1_right += get_grade\n",
    "                    part_possible += 1\n",
    "                    type1_possible += 1\n",
    "                elif json_obj[problem][part][question]['Classification'] == \"Type 2\":\n",
    "                    overlap_d = 2 * SequenceMatcher(None, json_obj[problem][part][question]['LLM Answer'], json_obj[problem][part][question]['Real Answer']).ratio()\n",
    "                    overlap_b = 2 * sentence_bleu([json_obj[problem][part][question]['Real Answer'].split()], json_obj[problem][part][question]['LLM Answer'].split())\n",
    "                    part_score += overlap_d\n",
    "                    part_possible += 2\n",
    "                    type2_right_b += overlap_b\n",
    "                    type2_right_a += get_grade\n",
    "                    type2_right_d += overlap_d\n",
    "                    type2_possible += 2\n",
    "                elif json_obj[problem][part][question]['Classification'] == \"Type 3\":\n",
    "                    part_score += get_grade\n",
    "                    part_possible += 2\n",
    "                    type3_right += get_grade\n",
    "                    type3_possible += 2\n",
    "                    \n",
    "            total_score += part_score\n",
    "            total_possible += part_possible\n",
    "    accuracy = total_score / total_possible\n",
    "    print(\"(\" + str(type3_possible) + \", \" + str(type3_right) + \"),\")\n",
    "    return total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right_a, type2_right_d, type2_right_b, type2_possible, type3_right, type3_possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_prob_parser(graded_data: json):\n",
    "    json_obj = graded_data\n",
    "    total_score = 0\n",
    "    total_possible = 0\n",
    "    total_questions = 0\n",
    "    type1_right = 0\n",
    "    type1_possible = 0\n",
    "    type2_right = 0\n",
    "    type2_possible = 0\n",
    "    type3_right = 0\n",
    "    type3_possible = 0\n",
    "    for problem in json_obj:\n",
    "        if problem[0:7] != \"Problem\":\n",
    "            continue\n",
    "        total_questions += 1\n",
    "        for part in json_obj[problem]:\n",
    "            part_score = 0\n",
    "            part_possible = 0\n",
    "            for question in json_obj[problem][part]:\n",
    "                if question[0:4] == \"Clas\":\n",
    "                    try:\n",
    "                        get_grade = int(json_obj[problem][part]['Grade'][0])\n",
    "                    except:\n",
    "                        get_grade = json_obj[problem][part]['Grade']\n",
    "                        \n",
    "                    if json_obj[problem][part]['Classification'] == \"Type 1\":\n",
    "                        part_score += get_grade\n",
    "                        type1_right += get_grade\n",
    "                        part_possible += 1\n",
    "                        type1_possible += 1\n",
    "                    elif json_obj[problem][part]['Classification'] == \"Type 2\":\n",
    "                        part_score += get_grade\n",
    "                        part_possible += 2\n",
    "                        type2_right += get_grade\n",
    "                        type2_possible += 2\n",
    "                    elif json_obj[problem][part]['Classification'] == \"Type 3\":\n",
    "                        part_score += get_grade\n",
    "                        part_possible += 2\n",
    "                        type3_right += get_grade\n",
    "                        type3_possible += 2\n",
    "                    break\n",
    "                # grading\n",
    "                try:\n",
    "                    get_grade = int(json_obj[problem][part][question]['Grade'][0])\n",
    "                except:\n",
    "                    get_grade = json_obj[problem][part][question]['Grade']\n",
    "                    \n",
    "                if json_obj[problem][part][question]['Classification'] == \"Type 1\":\n",
    "                    part_score += get_grade\n",
    "                    type1_right += get_grade\n",
    "                    part_possible += 1\n",
    "                    type1_possible += 1\n",
    "                elif json_obj[problem][part][question]['Classification'] == \"Type 2\":\n",
    "                    part_score += get_grade\n",
    "                    part_possible += 2\n",
    "                    type2_right += get_grade\n",
    "                    type2_possible += 2\n",
    "                elif json_obj[problem][part][question]['Classification'] == \"Type 3\":\n",
    "\n",
    "                    part_score += get_grade\n",
    "                    part_possible += 2\n",
    "                    type3_right += get_grade\n",
    "                    type3_possible += 2\n",
    "            total_score += part_score\n",
    "            total_possible += part_possible\n",
    "    accuracy = total_score / total_possible\n",
    "    return total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right, type2_possible, type3_right, type3_possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satyamgoyal/anaconda3/envs/lm_mentor/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/satyamgoyal/anaconda3/envs/lm_mentor/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/satyamgoyal/anaconda3/envs/lm_mentor/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/var/folders/5t/bmhkrbcn4yzgbdrrgwk7ps_r0000gn/T/ipykernel_90267/3611847134.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  eval_table = pd.concat([eval_table, pd.DataFrame([[year, model, total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right_a, type2_right_d, type2_right_b, type2_possible, type3_right, type3_possible]], columns=[\"Year\", \"Model\", \"Total Score\", \"Total Possible\", \"Accuracy\", \"Total Questions\", \"Type 1 Right\", \"Type 1 Possible\", \"Type 2 Right LLM\", \"Type 2 Right Diff\", \"Type 2 Right Bleu\", \"Type 2 Possible\", \"Type 3 Right\", \"Type 3 Possible\"])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1),\n",
      "(8, 1),\n",
      "(8, 3),\n",
      "(8, 4),\n",
      "(8, 3),\n",
      "(8, 2),\n",
      "(8, 4),\n",
      "(8, 2),\n",
      "(6, 4),\n",
      "(6, 2),\n",
      "(6, 4),\n",
      "(6, 1),\n",
      "(6, 4),\n",
      "(6, 1),\n",
      "(6, 1),\n",
      "(6, 6),\n",
      "(20, 10),\n",
      "(20, 5),\n",
      "(20, 8),\n",
      "(20, 3),\n",
      "(20, 10),\n",
      "(20, 6),\n",
      "(20, 11),\n",
      "(20, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 0),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 2),\n",
      "(2, 1),\n",
      "(2, 2),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(4, 2),\n",
      "(4, 2),\n",
      "(4, 1),\n",
      "(4, 0),\n",
      "(4, 2),\n",
      "(4, 1),\n",
      "(4, 2),\n",
      "(4, 2),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 0),\n",
      "(2, 0),\n",
      "(2, 0),\n",
      "(2, 1),\n",
      "(6, 1),\n",
      "(6, 2),\n",
      "(6, 2),\n",
      "(6, 4),\n",
      "(6, 1),\n",
      "(6, 2),\n",
      "(6, 0),\n",
      "(6, 1),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(4, 2),\n",
      "(4, 3),\n",
      "(4, 3),\n",
      "(4, 2),\n",
      "(4, 3),\n",
      "(4, 2),\n",
      "(4, 2),\n",
      "(4, 1),\n",
      "(4, 2),\n",
      "(4, 1),\n",
      "(4, 4),\n",
      "(4, 1),\n",
      "(4, 2),\n",
      "(4, 1),\n",
      "(4, 3),\n",
      "(4, 1),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(2, 1),\n",
      "(2, 0),\n",
      "(2, 0),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 0),\n",
      "(2, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(2, 0),\n",
      "(2, 0),\n",
      "(2, 0),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 0),\n",
      "(2, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 1),\n",
      "(2, 0),\n",
      "(2, 0),\n",
      "(2, 1),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n",
      "(0, 0),\n"
     ]
    }
   ],
   "source": [
    "years = [str(i) for i in range(2004, 2024)]\n",
    "# remove 2020\n",
    "years.append('samples')\n",
    "years.remove('2020')\n",
    "\n",
    "models = [\"gpt4o\", \"claude3.5s\", \"claude3o\", \"claude3h\", \"gemini1.5p\", \"gpt4\", \"gpt4om\", \"o1strawberry\"]\n",
    "\n",
    "eval_table = pd.DataFrame(columns=[\"Year\", \"Model\", \"Total Score\", \"Total Possible\", \"Accuracy\", \"Total Questions\", \"Type 1 Right\", \"Type 1 Possible\",\"Type 2 Right LLM\", \"Type 2 Right Diff\", \"Type 2 Right Bleu\", \"Type 2 Possible\", \"Type 3 Right\", \"Type 3 Possible\"])\n",
    "\n",
    "# add blank rows to eval_table\n",
    "for year in years:\n",
    "    for model in models:\n",
    "        path = '../iol_' + year + '/' + model + '/evaluation.txt'\n",
    "        if year == 'samples':\n",
    "            path = '../iol_samples/text/' + model + '/evaluation.txt'\n",
    "        json_obj = text_to_json(path)\n",
    "        if json_obj:\n",
    "            #print(f\"Proc essing year {year} for model {model}\")\n",
    "            total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right_a, type2_right_d, type2_right_b, type2_possible, type3_right, type3_possible = grad_parser(json_obj)\n",
    "\n",
    "            # if accuracy < 0.1:\n",
    "            #     print(f\"Processing year {year} for model {model}\")\n",
    "            #     print(f\"Total Score: {total_score}/{total_possible}\")\n",
    "            #     print(f\"Accuracy: {accuracy}\")\n",
    "            \n",
    "            \n",
    "            eval_table = pd.concat([eval_table, pd.DataFrame([[year, model, total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right_a, type2_right_d, type2_right_b, type2_possible, type3_right, type3_possible]], columns=[\"Year\", \"Model\", \"Total Score\", \"Total Possible\", \"Accuracy\", \"Total Questions\", \"Type 1 Right\", \"Type 1 Possible\", \"Type 2 Right LLM\", \"Type 2 Right Diff\", \"Type 2 Right Bleu\", \"Type 2 Possible\", \"Type 3 Right\", \"Type 3 Possible\"])], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Error processing year {year} for model {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "type3right_manual = [(8, 1),\n",
    "(8, 1),\n",
    "(8, 3),\n",
    "(8, 4),\n",
    "(8, 3),\n",
    "(8, 2),\n",
    "(8, 4),\n",
    "(8, 4),\n",
    "(6, 4),\n",
    "(6, 2),\n",
    "(6, 4),\n",
    "(6, 1),\n",
    "(6, 4),\n",
    "(6, 1),\n",
    "(6, 1),\n",
    "(6, 6),\n",
    "(20, 10),\n",
    "(20, 5),\n",
    "(20, 8),\n",
    "(20, 3),\n",
    "(20, 10),\n",
    "(20, 6),\n",
    "(20, 1),\n",
    "(20, 12),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 0),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 2),\n",
    "(2, 1),\n",
    "(2, 2),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(4, 2),\n",
    "(4, 2),\n",
    "(4, 1),\n",
    "(4, 0),\n",
    "(4, 2),\n",
    "(4, 1),\n",
    "(4, 2),\n",
    "(4, 3),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 0),\n",
    "(2, 0),\n",
    "(2, 0),\n",
    "(2, 2),\n",
    "(6, 1),\n",
    "(6, 2),\n",
    "(6, 2),\n",
    "(6, 4),\n",
    "(6, 1),\n",
    "(6, 2),\n",
    "(6, 0),\n",
    "(6, 3),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(4, 2),\n",
    "(4, 3),\n",
    "(4, 3),\n",
    "(4, 2),\n",
    "(4, 3),\n",
    "(4, 2),\n",
    "(4, 2),\n",
    "(4, 1),\n",
    "(4, 2),\n",
    "(4, 1),\n",
    "(4, 4),\n",
    "(4, 1),\n",
    "(4, 2),\n",
    "(4, 1),\n",
    "(4, 3),\n",
    "(4, 2),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(2, 1),\n",
    "(2, 0),\n",
    "(2, 0),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 0),\n",
    "(2, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(2, 0),\n",
    "(2, 0),\n",
    "(2, 0),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 0),\n",
    "(2, 2),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 1),\n",
    "(2, 0),\n",
    "(2, 0),\n",
    "(2, 1),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0),\n",
    "(0, 0)]\n",
    "\n",
    "type3right = [i[1] for i in type3right_manual]\n",
    "\n",
    "eval_table['Type 3 Right Manual'] = type3right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add vision problems\n",
    "years = ['2010v','2011v']\n",
    "\n",
    "models = [\"gpt4o\", \"claude3.5s\", \"claude3o\", \"claude3h\", \"gemini1.5p\", \"gpt4\", \"gpt4om\"]\n",
    "\n",
    "eval_table_v = pd.DataFrame(columns=[\"Year\", \"Model\", \"Total Score\", \"Total Possible\", \"Accuracy\", \"Total Questions\", \"Type 1 Right\", \"Type 1 Possible\",\"Type 2 Right\", \"Type 2 Possible\", \"Type 3 Right\", \"Type 3 Possible\"])\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    for model in models:\n",
    "        if year == '2010':\n",
    "            path = '../iol_2010/' + model + '/evaluation_3.txt'\n",
    "        else:\n",
    "            path = '../iol_2011/' + model + '/evaluation_5.txt'\n",
    "        json_obj = text_to_json(path)\n",
    "        if json_obj:\n",
    "            total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right, type2_possible, type3_right, type3_possible = vision_prob_parser(json_obj)\n",
    "\n",
    "            if accuracy > 0.75:\n",
    "                print(f\"Processing year {year} for model {model}\")\n",
    "                print(f\"Total Score: {total_score}/{total_possible}\")\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "            \n",
    "            \n",
    "            eval_table_v = pd.concat([eval_table_v, pd.DataFrame([[year, model, total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right,  type2_possible, type3_right, type3_possible]], columns=[\"Year\", \"Model\", \"Total Score\", \"Total Possible\", \"Accuracy\", \"Total Questions\", \"Type 1 Right\", \"Type 1 Possible\", \"Type 2 Right\", \"Type 2 Possible\", \"Type 3 Right\", \"Type 3 Possible\"])], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Error processing year {year} for model {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/bmhkrbcn4yzgbdrrgwk7ps_r0000gn/T/ipykernel_90267/3290123000.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  eval_table_v = pd.concat([eval_table_v, pd.DataFrame([[year, model, total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right,  type2_possible, type3_right, type3_possible]], columns=[\"Year\", \"Model\", \"Total Score\", \"Total Possible\", \"Accuracy\", \"Total Questions\", \"Type 1 Right\", \"Type 1 Possible\", \"Type 2 Right\", \"Type 2 Possible\", \"Type 3 Right\", \"Type 3 Possible\"])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# add vision problems\n",
    "years = ['2010v','2011v']\n",
    "\n",
    "models = [\"gpt4o\", \"claude3.5s\", \"claude3o\", \"claude3h\", \"gemini1.5p\", \"gpt4\", \"gpt4om\"]\n",
    "\n",
    "eval_table_v = pd.DataFrame(columns=[\"Year\", \"Model\", \"Total Score\", \"Total Possible\", \"Accuracy\", \"Total Questions\", \"Type 1 Right\", \"Type 1 Possible\",\"Type 2 Right\", \"Type 2 Possible\", \"Type 3 Right\", \"Type 3 Possible\"])\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    for model in models:\n",
    "        if year == '2010':\n",
    "            path = '../iol_2010/' + model + '/evaluation_3.txt'\n",
    "        else:\n",
    "            path = '../iol_2011/' + model + '/evaluation_5.txt'\n",
    "        json_obj = text_to_json(path)\n",
    "        if json_obj:\n",
    "            total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right, type2_possible, type3_right, type3_possible = vision_prob_parser(json_obj)\n",
    "\n",
    "            if accuracy > 0.75:\n",
    "                print(f\"Processing year {year} for model {model}\")\n",
    "                print(f\"Total Score: {total_score}/{total_possible}\")\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "            \n",
    "            \n",
    "            eval_table_v = pd.concat([eval_table_v, pd.DataFrame([[year, model, total_score, total_possible, accuracy, total_questions, type1_right, type1_possible, type2_right,  type2_possible, type3_right, type3_possible]], columns=[\"Year\", \"Model\", \"Total Score\", \"Total Possible\", \"Accuracy\", \"Total Questions\", \"Type 1 Right\", \"Type 1 Possible\", \"Type 2 Right\", \"Type 2 Possible\", \"Type 3 Right\", \"Type 3 Possible\"])], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Error processing year {year} for model {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_table.to_csv(\"eval_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_table_v.to_csv(\"eval_table_v.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Model</th>\n",
       "      <th>Total Score</th>\n",
       "      <th>Total Possible</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Total Questions</th>\n",
       "      <th>Type 1 Right</th>\n",
       "      <th>Type 1 Possible</th>\n",
       "      <th>Type 2 Right LLM</th>\n",
       "      <th>Type 2 Right Diff</th>\n",
       "      <th>Type 2 Right Bleu</th>\n",
       "      <th>Type 2 Possible</th>\n",
       "      <th>Type 3 Right</th>\n",
       "      <th>Type 3 Possible</th>\n",
       "      <th>Type 3 Right Manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>19.981644</td>\n",
       "      <td>45</td>\n",
       "      <td>0.444037</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>15.981644</td>\n",
       "      <td>3.286918</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>claude3.5s</td>\n",
       "      <td>22.132561</td>\n",
       "      <td>45</td>\n",
       "      <td>0.491835</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>16.132561</td>\n",
       "      <td>2.271757</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>claude3o</td>\n",
       "      <td>26.834697</td>\n",
       "      <td>45</td>\n",
       "      <td>0.596327</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>18.834697</td>\n",
       "      <td>3.298447</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>claude3h</td>\n",
       "      <td>22.951422</td>\n",
       "      <td>45</td>\n",
       "      <td>0.510032</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>16.951422</td>\n",
       "      <td>3.960966</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>gemini1.5p</td>\n",
       "      <td>17.979579</td>\n",
       "      <td>45</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12.979579</td>\n",
       "      <td>0.822267</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>samples</td>\n",
       "      <td>claude3h</td>\n",
       "      <td>116.445351</td>\n",
       "      <td>204</td>\n",
       "      <td>0.570811</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>94</td>\n",
       "      <td>49</td>\n",
       "      <td>73.445351</td>\n",
       "      <td>26.635306</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>samples</td>\n",
       "      <td>gemini1.5p</td>\n",
       "      <td>111.465203</td>\n",
       "      <td>190</td>\n",
       "      <td>0.586659</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "      <td>76.465203</td>\n",
       "      <td>17.512947</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>samples</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>113.291018</td>\n",
       "      <td>212</td>\n",
       "      <td>0.534392</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>94</td>\n",
       "      <td>46</td>\n",
       "      <td>80.291018</td>\n",
       "      <td>3.352702</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>samples</td>\n",
       "      <td>gpt4om</td>\n",
       "      <td>68.376404</td>\n",
       "      <td>183</td>\n",
       "      <td>0.373642</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>91</td>\n",
       "      <td>28</td>\n",
       "      <td>51.376404</td>\n",
       "      <td>5.337481</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>samples</td>\n",
       "      <td>o1strawberry</td>\n",
       "      <td>132.623739</td>\n",
       "      <td>186</td>\n",
       "      <td>0.713031</td>\n",
       "      <td>12</td>\n",
       "      <td>75</td>\n",
       "      <td>94</td>\n",
       "      <td>42</td>\n",
       "      <td>57.623739</td>\n",
       "      <td>14.720364</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year         Model  Total Score Total Possible  Accuracy  \\\n",
       "0       2004         gpt4o    19.981644             45  0.444037   \n",
       "1       2004    claude3.5s    22.132561             45  0.491835   \n",
       "2       2004      claude3o    26.834697             45  0.596327   \n",
       "3       2004      claude3h    22.951422             45  0.510032   \n",
       "4       2004    gemini1.5p    17.979579             45  0.399546   \n",
       "..       ...           ...          ...            ...       ...   \n",
       "155  samples      claude3h   116.445351            204  0.570811   \n",
       "156  samples    gemini1.5p   111.465203            190  0.586659   \n",
       "157  samples          gpt4   113.291018            212  0.534392   \n",
       "158  samples        gpt4om    68.376404            183  0.373642   \n",
       "159  samples  o1strawberry   132.623739            186  0.713031   \n",
       "\n",
       "    Total Questions Type 1 Right Type 1 Possible Type 2 Right LLM  \\\n",
       "0                 5            3              13                7   \n",
       "1                 5            5              13               11   \n",
       "2                 5            5              13               15   \n",
       "3                 5            2              13               12   \n",
       "4                 5            2              13                5   \n",
       "..              ...          ...             ...              ...   \n",
       "155              12           43              94               49   \n",
       "156              12           35              80               58   \n",
       "157              12           33              94               46   \n",
       "158              12           17              91               28   \n",
       "159              12           75              94               42   \n",
       "\n",
       "     Type 2 Right Diff  Type 2 Right Bleu Type 2 Possible Type 3 Right  \\\n",
       "0            15.981644           3.286918              24            1   \n",
       "1            16.132561           2.271757              24            1   \n",
       "2            18.834697           3.298447              24            3   \n",
       "3            16.951422           3.960966              24            4   \n",
       "4            12.979579           0.822267              24            3   \n",
       "..                 ...                ...             ...          ...   \n",
       "155          73.445351          26.635306             110            0   \n",
       "156          76.465203          17.512947             110            0   \n",
       "157          80.291018           3.352702             118            0   \n",
       "158          51.376404           5.337481              92            0   \n",
       "159          57.623739          14.720364              92            0   \n",
       "\n",
       "    Type 3 Possible  Type 3 Right Manual  \n",
       "0                 8                    1  \n",
       "1                 8                    1  \n",
       "2                 8                    3  \n",
       "3                 8                    4  \n",
       "4                 8                    3  \n",
       "..              ...                  ...  \n",
       "155               0                    0  \n",
       "156               0                    0  \n",
       "157               0                    0  \n",
       "158               0                    0  \n",
       "159               0                    0  \n",
       "\n",
       "[160 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Model</th>\n",
       "      <th>Total Score</th>\n",
       "      <th>Total Possible</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Total Questions</th>\n",
       "      <th>Type 1 Right</th>\n",
       "      <th>Type 1 Possible</th>\n",
       "      <th>Type 2 Right</th>\n",
       "      <th>Type 2 Possible</th>\n",
       "      <th>Type 3 Right</th>\n",
       "      <th>Type 3 Possible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010v</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010v</td>\n",
       "      <td>claude3.5s</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010v</td>\n",
       "      <td>claude3o</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010v</td>\n",
       "      <td>claude3h</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010v</td>\n",
       "      <td>gemini1.5p</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010v</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010v</td>\n",
       "      <td>gpt4om</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011v</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011v</td>\n",
       "      <td>claude3.5s</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011v</td>\n",
       "      <td>claude3o</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011v</td>\n",
       "      <td>claude3h</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011v</td>\n",
       "      <td>gemini1.5p</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2011v</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2011v</td>\n",
       "      <td>gpt4om</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year       Model Total Score Total Possible  Accuracy Total Questions  \\\n",
       "0   2010v       gpt4o           4             16    0.2500               1   \n",
       "1   2010v  claude3.5s           4             16    0.2500               1   \n",
       "2   2010v    claude3o           2             16    0.1250               1   \n",
       "3   2010v    claude3h           0             16    0.0000               1   \n",
       "4   2010v  gemini1.5p           4             16    0.2500               1   \n",
       "5   2010v        gpt4           1             16    0.0625               1   \n",
       "6   2010v      gpt4om           2             16    0.1250               1   \n",
       "7   2011v       gpt4o           4             16    0.2500               1   \n",
       "8   2011v  claude3.5s           4             16    0.2500               1   \n",
       "9   2011v    claude3o           2             16    0.1250               1   \n",
       "10  2011v    claude3h           0             16    0.0000               1   \n",
       "11  2011v  gemini1.5p           4             16    0.2500               1   \n",
       "12  2011v        gpt4           1             16    0.0625               1   \n",
       "13  2011v      gpt4om           2             16    0.1250               1   \n",
       "\n",
       "   Type 1 Right Type 1 Possible Type 2 Right Type 2 Possible Type 3 Right  \\\n",
       "0             2               6            2              10            0   \n",
       "1             1               6            3              10            0   \n",
       "2             1               6            1              10            0   \n",
       "3             0               6            0              10            0   \n",
       "4             2               6            2              10            0   \n",
       "5             1               6            0              10            0   \n",
       "6             1               6            1              10            0   \n",
       "7             2               6            2              10            0   \n",
       "8             1               6            3              10            0   \n",
       "9             1               6            1              10            0   \n",
       "10            0               6            0              10            0   \n",
       "11            2               6            2              10            0   \n",
       "12            1               6            0              10            0   \n",
       "13            1               6            1              10            0   \n",
       "\n",
       "   Type 3 Possible  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "5                0  \n",
       "6                0  \n",
       "7                0  \n",
       "8                0  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_table_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "claude3.5s    0.166667\n",
      "claude3h           0.0\n",
      "claude3o      0.166667\n",
      "gemini1.5p    0.333333\n",
      "gpt4          0.166667\n",
      "gpt4o         0.333333\n",
      "gpt4om        0.166667\n",
      "Name: Type 1 Percentage, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of Type 1 Right for each row\n",
    "eval_table_v['Type 1 Percentage'] = eval_table_v['Type 1 Right'] / eval_table_v['Type 1 Possible']\n",
    "\n",
    "# Group by 'Model' and calculate the mean percentage of Type 1 Right for each model\n",
    "type1_percentage_by_model_v = eval_table_v.groupby('Model')['Type 1 Percentage'].mean()\n",
    "\n",
    "# Display the result\n",
    "print(type1_percentage_by_model_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "claude3.5s    0.3\n",
      "claude3h      0.0\n",
      "claude3o      0.1\n",
      "gemini1.5p    0.2\n",
      "gpt4          0.0\n",
      "gpt4o         0.2\n",
      "gpt4om        0.1\n",
      "Name: Type 2 Percentage, dtype: object\n"
     ]
    }
   ],
   "source": [
    "eval_table_v['Type 2 Percentage'] = eval_table_v['Type 2 Right'] / eval_table_v['Type 2 Possible']\n",
    "\n",
    "type2_percentage_by_model_v = eval_table_v.groupby('Model')['Type 2 Percentage'].mean()\n",
    "\n",
    "print(type2_percentage_by_model_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "claude3.5s    0.0\n",
      "claude3h      0.0\n",
      "claude3o      0.0\n",
      "gemini1.5p    0.0\n",
      "gpt4          0.0\n",
      "gpt4o         0.0\n",
      "gpt4om        0.0\n",
      "Name: Type 3 Percentage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "eval_table_v['Type 3 Percentage'] = eval_table_v.apply(\n",
    "    lambda row: (row['Type 3 Right'] / row['Type 3 Possible']) * 100 if row['Type 3 Possible'] > 0 else\n",
    "    0, axis=1\n",
    ")\n",
    "type3_percentage_by_model_v = eval_table_v.groupby('Model')['Type 3 Percentage'].mean()\n",
    "\n",
    "print(type3_percentage_by_model_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "claude3.5s      37.471159\n",
      "claude3h         18.11579\n",
      "claude3o        37.031134\n",
      "gemini1.5p      18.896007\n",
      "gpt4            21.384711\n",
      "gpt4o           27.301799\n",
      "gpt4om          21.553478\n",
      "o1strawberry    28.459939\n",
      "Name: Type 1 Percentage, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of Type 1 Right for each row\n",
    "eval_table['Type 1 Percentage'] = (eval_table['Type 1 Right'] / eval_table['Type 1 Possible']) * 100\n",
    "\n",
    "# Group by 'Model' and calculate the mean percentage of Type 1 Right for each model\n",
    "type1_percentage_by_model = eval_table.groupby('Model')['Type 1 Percentage'].mean()\n",
    "\n",
    "# Display the result\n",
    "print(type1_percentage_by_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "claude3.5s      59.914754\n",
      "claude3h        43.009400\n",
      "claude3o        48.733995\n",
      "gemini1.5p      40.471049\n",
      "gpt4            37.701040\n",
      "gpt4o           39.252441\n",
      "gpt4om          31.172195\n",
      "o1strawberry    46.879788\n",
      "Name: Type 2 Percentage LLM Graded, dtype: float64\n",
      "Model\n",
      "claude3.5s      22.861759\n",
      "claude3h        17.180799\n",
      "claude3o        10.909842\n",
      "gemini1.5p       7.750653\n",
      "gpt4            10.905816\n",
      "gpt4o            7.300873\n",
      "gpt4om           6.200295\n",
      "o1strawberry    10.414871\n",
      "Name: Type 2 Right Bleu Score, dtype: float64\n",
      "Model\n",
      "claude3.5s      76.984018\n",
      "claude3h        63.100367\n",
      "claude3o        62.365016\n",
      "gemini1.5p      57.564699\n",
      "gpt4            63.887071\n",
      "gpt4o           60.831881\n",
      "gpt4om          54.183915\n",
      "o1strawberry    65.893937\n",
      "Name: Type 2 Right Diff Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of Type 1 Right for each row\n",
    "\n",
    "eval_table['Type 2 Percentage LLM Graded'] = eval_table.apply(\n",
    "    lambda row: (row['Type 2 Right LLM'] / row['Type 2 Possible']) * 100 if row['Type 2 Right LLM'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "eval_table['Type 2 Right Bleu Score'] = eval_table.apply(\n",
    "    lambda row: (row['Type 2 Right Bleu'] / row['Type 2 Possible']) * 100 if row['Type 2 Right Bleu'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "eval_table['Type 2 Right Diff Score'] = eval_table.apply(\n",
    "    lambda row: (row['Type 2 Right Diff'] / row['Type 2 Possible']) * 100 if row['Type 2 Right Diff'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Group by 'Model' and calculate the mean percentage of Type 1 Right for each model\n",
    "type2_llm_percentage_by_model = eval_table.groupby('Model')['Type 2 Percentage LLM Graded'].mean()\n",
    "\n",
    "type2_bleu_percentage_by_model = eval_table.groupby('Model')['Type 2 Right Bleu Score'].mean()\n",
    "\n",
    "type2_diff_percentage_by_model = eval_table.groupby('Model')['Type 2 Right Diff Score'].mean()\n",
    "\n",
    "# Display the result\n",
    "print(type2_llm_percentage_by_model)\n",
    "\n",
    "print(type2_bleu_percentage_by_model)\n",
    "\n",
    "print(type2_diff_percentage_by_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "claude3.5s      38.782051\n",
      "claude3h        40.256410\n",
      "claude3o        44.423077\n",
      "gemini1.5p      45.833333\n",
      "gpt4            31.153846\n",
      "gpt4o           41.987179\n",
      "gpt4om          30.512821\n",
      "o1strawberry    33.974359\n",
      "Name: Type 3 Percentage LLM Graded, dtype: float64\n",
      "Model\n",
      "claude3.5s      38.782051\n",
      "claude3h        40.256410\n",
      "claude3o        44.423077\n",
      "gemini1.5p      45.833333\n",
      "gpt4            31.153846\n",
      "gpt4o           41.987179\n",
      "gpt4om          26.666667\n",
      "o1strawberry    58.461538\n",
      "Name: Type 3 Percentage Manual Graded, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# remove rows with 0 possible questions\n",
    "\n",
    "eval_table_c = eval_table[eval_table['Type 3 Possible'] > 0].copy()\n",
    "\n",
    "eval_table_c['Type 3 Percentage LLM Graded'] = eval_table_c.apply(\n",
    "    lambda row: (row['Type 3 Right'] / row['Type 3 Possible']) * 100 if row['Type 3 Possible'] > 0 else\n",
    "    0, axis=1\n",
    ")\n",
    "\n",
    "eval_table_c['Type 3 Percentage Manual Graded'] = eval_table_c.apply(\n",
    "    lambda row: (row['Type 3 Right Manual'] / row['Type 3 Possible']) * 100 if row['Type 3 Possible'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Group by 'Model' and calculate the mean percentage of Type 1 Right for each model\n",
    "type3_llm_percentage_by_model = eval_table_c.groupby('Model')['Type 3 Percentage LLM Graded'].mean()\n",
    "\n",
    "type3_man_percentage_by_model = eval_table_c.groupby('Model')['Type 3 Percentage Manual Graded'].mean()\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(type3_llm_percentage_by_model)\n",
    "print(type3_man_percentage_by_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_mentor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
